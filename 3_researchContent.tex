%%%%% --------------------------------------------------------------------------------
%%
%%%%******************************* Main Content *************************************
%%
%%% ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++




\section{研究内容}

\subsection{研究目标}
用问题来引出“科学识人”的现实需求。

科学识人是社会生产生活实践的现实需要和普遍追求，大到各级组织的选人用人和人才工作质效、小到日常社会交往中的朋友圈、兴趣圈，都离不开对人的准确认识。
随着信息技术的发展，大数据驱动的用户画像技术在电商平台、社交媒体和科研文献数据库等特定领域中发挥了重要作用，能够帮助用户在纷繁复杂的互联网中快速了解彼此。
然而，互联网上的用户画像技术并不能代表广泛意义上的科学识人，它们有着明确的任务背景和现实需求，数据的特异性决定了方法的专用性，因此可能难以适用于其他的任务。
广义上的科学识人，应当是人认识人的过程，其主体和客体都是人。
人的复杂性是科学识人面临的关键挑战，一方面，社会中不同个体之间相互认知、相互建模的普遍行为构成了科学识人的基本内涵；
另一方面，人类心智认识事物的普遍能力蕴含了科学识人的基本规律。
可见，科学识人本身是一种智能行为，实现数据驱动的广义科学识人需要深入理解人的复杂性，解析人员画像行为和心智认知能力。

因此，本研究的目标是解决真实社会场景下关于人员画像和心智建模的关键理论和技术问题。
其中，人员画像和心智建模本质上都可以被解释为贝叶斯推断，即根据事实证据在假设空间中寻找到似然度最好的那些假设，人员画像研究的是推断的过程，心智建模研究的是推断能力本身，两者是互为表里的关系。

就人员画像而言，这是一个语义十分宽泛的概念，因此本研究先尝试厘清其概念内涵。
在人资场景下，狭义的人员画像通常被理解为是依托某种胜任力模型的人员分类、打分、排序等具体评价任务，具有较强的专业任务背景。
而在人类社会乃至自然环境中，广义的人员画像其实是人类个体对其他个体的一种普遍的认知行为和能力。
本研究主要关注广义的人员画像问题，即如何用贝叶斯相关理论在数学形式上描述人员画像的普遍行为以及如何基于理论改进相关技术。

就心智而言，这是一个充满未知与挑战同时又十分诱人的领域，诸多睿智的科研先驱们前赴后继乐此不疲地投入到相关的研究工作中，时至今日要揭开心智神秘面纱的一角却依然显得举步维艰。
本研究聚焦人类在认识事物过程中的极为平凡的一种学习能力——高效归纳能力，并尝试在特定任务中用机器模拟和复刻这种能力。


\centerline{\rule[5pt]{\textwidth+2mm}{0.7pt}}% 表格中分割横线，勿删

\subsection{主要研究内容}
本研究将尝试基于贝叶斯相关理论对真实世界中的人员画像过程进行统一的建模和描述，
从而利用贝叶斯推断的理论优势来解决实际人员画像任务中面临的数据稀缺和建模成本昂贵的挑战，即解决有模型推断和无模型推断的关键算法问题。
同时，本研究还将尝试基于主动推断框架模拟人类的认知过程，即实现一种具有高效归纳能力的学习算法。

\subsubsection{少样本约束下基于胜任力模型的推断算法研究}
在人资场景下，基于胜任力模型的人员画像是极为常见的任务需求，然而在实际运行过程中，往往存在用于画像的数据不足、失准、矛盾等信息质量问题，给人员画像的精细度、准确度带来一定挑战。
如何从有限的数据样本中充分利用和挖掘有价值的信息，并进行高效的推断是一个亟待解决的关键问题。
贝叶斯推断的工作流能够从较少的数据中充分利用信息来更新先验假设，并具有历时性的特点，十分适合少样本约束下基于胜任力模型的人员画像任务。
但贝叶斯推断本身存在着计算复杂度高、高度依赖先验等问题，实际应用时如何执行近似推断、合理估计先验、提升推断过程鲁棒性等，将是本研究面临的主要挑战。

\subsubsection{基于数据的迭代推断和胜任力模型优化方法研究}
对于人资场景下的人员画像任务，胜任力模型往往被视为超参数固定下来，其决定了搜索的“假设空间”。
对于贝叶斯推断的工作流来说，确定的“假设空间”意味着选择用来近似后验的分布族，是会影响最终推断结果的。
这反映出用不同的胜任力模型做人员画像时的效果优劣，更适合的胜任力模型对应着更合理的“假设空间”，进而对应着更贴合的近似后验分布族。
在人资场景中，如何选择胜任力模型是一个十分关键的先决问题，其需要依靠丰富的专家经验和领域知识来加以确定。
然而，在人类进行人员画像行为的过程中却并非如此，胜任力模型所代表的“标准”不是一成不变的，而是和画像的后验一样，随着推断的行为而不断迭代演化的。
因此，本研究认为人员画像所依赖的胜任力模型是不完美的，是需要在人员画像的过程中迭代优化的，如何建立起同时兼容人员画像推断和胜任力模型优化过程的迭代框架是本研究面临的关键挑战。

\subsubsection{基于变分自由能原理的机器归纳算法研究}
归纳能力普遍被认为是人类所具有的十分重要的“元学习”能力，是一种根据观测事实进行抽象和推理并提炼知识的高效学习能力\upcite{tenenbaum2011grow}。
理解归纳能力的本质对于理解人类心智和大脑工作机制以及实现通用人工智能有着重要的理论意义，同时对于人资场景下实现更广泛更普适的“科学识人”有着重要的现实意义。



\centerline{\rule[5pt]{\textwidth+2mm}{0.7pt}}% 表格中分割横线，勿删

\subsection{工作方案及可行性分析}

\subsubsection{研究方法}
本研究首先用贝叶斯理论对人员画像做一个数学形式上的定义：

认识一个人时，可以用一组随机变量来描述，并根据可观测与否可分为潜变量$z$和显变量$x$。
对人的整体认识用联合概率分布$P(x,z)$来表述，人与人之间的差异反映为概率分布的差异。
在实际人员画像问题中，显变量$x$对应人的行为数据，是画像的依据；潜变量$z$对应人的能力潜质，是画像的目标。

胜任力模型反映为$P(x,z)$各变量间的依赖结构，即概率图结构$G$。
通常认为潜变量$z$位于图的上游，代表原因，而显变量$x$位于图的下游，代表结果。
因此，基于胜任力模型的人员画像问题就可以形式化为在概率图确定的情况下，对隐变量后验的推断问题：
\begin{equation}
    P(z|x,G) = \frac{P(x|z,G)P(z|G)}{P(x|G)}
\end{equation}

而无模型的人员画像，则将概率图结构本身也纳入推断的目标：
\begin{equation}
    P(z,G|x) = \frac{P(x|z,G)P(z,G)}{P(x|z,G)}
\end{equation}
其中，$P(G)$是关于概率图结构的单变量有限状态分布，并且约束不同的$P(x,z)$共享相同的$G$。

人类对他人进行画像的行为，可以理解为是基于观测信息$x$对潜在$G$的推断，是一种更广义的无模型人员画像，因为$z$的概率空间是不确定的。
这种画像行为的能力可能表现在$G$的生长过程中，是人类归纳能力的重要体现。


\subsubsection{技术路线}
本研究将着眼真实世界中的任务场景需求开展实证分析：

比如，高度动态的人员画像问题是一个现实的画像难题，常见于社会网络传播中的用户画像场景。
其使用的数据大多为流式数据，对画像的实时性和可解释性有着较高的要求，如何兼顾个体行为的历史和当下来预测接下来的行为是其面临的主要挑战。
有模型推断方法相比于深度学习方法能够提供良好的可解释性，同时能够更好的适应实时性的画像更新需求。

又比如，多视图人员画像是另一个现实的画像难题，常见于人力资源管理任务中的人员评价场景。
其使用的数据具有多源异构的特点，对画像方法的可扩展性和可解释性有着较高的要求，难以用统一的胜任力模型来分析和解释多源异构的数据。
无模型推断方法能够在推断的过程中不断优化模型，相比于现有传统评价方法，能够降低胜任力模型构建的成本。

对于心智建模问题，本研究将着眼网格图的抽象推理任务数据集ARC-AGI开展实验探索。
ARC-AGI是Kaggle上的一项赛事任务，旨在为通用人工智能提供一个评测基准。
评测的每道题目都蕴含着一条抽象的变化规律，通过变化前后的两幅网格图来呈现，
人类可以很容易从中总结出规律并用于对变化的预测，而现有的人工智能系统则对此感到棘手。
ARC-AGI任务的数据相比于传统机器学习任务具有极少样本、表示稀疏的特点，也更符合人类学习的场景。

\centerline{\rule[5pt]{\textwidth+2mm}{0.7pt}}% 表格中分割横线，勿删
\subsection{预期创新点}
本研究首先对人员画像问题进行统一的描述和定义，将真实场景中的画像问题抽象为数学形式上的推断问题。

1.对于胜任力模型确定的人员画像任务，本研究探索少样本约束下的有模型高效推断方法，从而解决真实场景中人高度动态的人员画像问题。

2.对于缺少胜任力模型的人员画像问题，本研究探索在迭代推断过程中基于数据的胜任力模型优化方法，从而解决胜任力模型构建成本昂贵的问题。

3.对于理解人员画像的行为本身，本研究探索基于推断的归纳能力模拟方法，从而为理解人类心智提供一条可能的实证分析路径。



%%% ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
